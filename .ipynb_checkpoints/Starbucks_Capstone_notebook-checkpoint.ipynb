{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starbucks Capstone Challenge\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This data set contains simulated data that mimics customer behavior on the Starbucks rewards mobile app. Once every few days, Starbucks sends out an offer to users of the mobile app. An offer can be merely an advertisement for a drink or an actual offer such as a discount or BOGO (buy one get one free). Some users might not receive any offer during certain weeks. \n",
    "\n",
    "Not all users receive the same offer, and that is the challenge to solve with this data set.\n",
    "\n",
    "Your task is to combine transaction, demographic and offer data to determine which demographic groups respond best to which offer type. This data set is a simplified version of the real Starbucks app because the underlying simulator only has one product whereas Starbucks actually sells dozens of products.\n",
    "\n",
    "Every offer has a validity period before the offer expires. As an example, a BOGO offer might be valid for only 5 days. You'll see in the data set that informational offers have a validity period even though these ads are merely providing information about a product; for example, if an informational offer has 7 days of validity, you can assume the customer is feeling the influence of the offer for 7 days after receiving the advertisement.\n",
    "\n",
    "You'll be given transactional data showing user purchases made on the app including the timestamp of purchase and the amount of money spent on a purchase. This transactional data also has a record for each offer that a user receives as well as a record for when a user actually views the offer. There are also records for when a user completes an offer. \n",
    "\n",
    "Keep in mind as well that someone using the app might make a purchase through the app without having received an offer or seen an offer.\n",
    "\n",
    "### Example\n",
    "\n",
    "To give an example, a user could receive a discount offer buy 10 dollars get 2 off on Monday. The offer is valid for 10 days from receipt. If the customer accumulates at least 10 dollars in purchases during the validity period, the customer completes the offer.\n",
    "\n",
    "However, there are a few things to watch out for in this data set. Customers do not opt into the offers that they receive; in other words, a user can receive an offer, never actually view the offer, and still complete the offer. For example, a user might receive the \"buy 10 dollars get 2 dollars off offer\", but the user never opens the offer during the 10 day validity period. The customer spends 15 dollars during those ten days. There will be an offer completion record in the data set; however, the customer was not influenced by the offer because the customer never viewed the offer.\n",
    "\n",
    "### Cleaning\n",
    "\n",
    "This makes data cleaning especially important and tricky.\n",
    "\n",
    "You'll also want to take into account that some demographic groups will make purchases even if they don't receive an offer. From a business perspective, if a customer is going to make a 10 dollar purchase without an offer anyway, you wouldn't want to send a buy 10 dollars get 2 dollars off offer. You'll want to try to assess what a certain demographic group will buy when not receiving any offers.\n",
    "\n",
    "### Final Advice\n",
    "\n",
    "Because this is a capstone project, you are free to analyze the data any way you see fit. For example, you could build a machine learning model that predicts how much someone will spend based on demographics and offer type. Or you could build a model that predicts whether or not someone will respond to an offer. Or, you don't need to build a machine learning model at all. You could develop a set of heuristics that determine what offer you should send to each customer (ie 75 percent of women customers who were 35 years old responded to offer A vs 40 percent from the same demographic to offer B, so send offer A)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sets\n",
    "\n",
    "The data is contained in three files:\n",
    "\n",
    "* portfolio.json - containing offer ids and meta data about each offer (duration, type, etc.)\n",
    "* profile.json - demographic data for each customer\n",
    "* transcript.json - records for transactions, offers received, offers viewed, and offers completed\n",
    "\n",
    "Here is the schema and explanation of each variable in the files:\n",
    "\n",
    "**portfolio.json**\n",
    "* id (string) - offer id\n",
    "* offer_type (string) - type of offer ie BOGO, discount, informational\n",
    "* difficulty (int) - minimum required spend to complete an offer\n",
    "* reward (int) - reward given for completing an offer\n",
    "* duration (int) - \n",
    "* channels (list of strings)\n",
    "\n",
    "**profile.json**\n",
    "* age (int) - age of the customer \n",
    "* became_member_on (int) - date when customer created an app account\n",
    "* gender (str) - gender of the customer (note some entries contain 'O' for other rather than M or F)\n",
    "* id (str) - customer id\n",
    "* income (float) - customer's income\n",
    "\n",
    "**transcript.json**\n",
    "* event (str) - record description (ie transaction, offer received, offer viewed, etc.)\n",
    "* person (str) - customer id\n",
    "* time (int) - time in hours. The data begins at time t=0\n",
    "* value - (dict of strings) - either an offer id or transaction amount depending on the record\n",
    "\n",
    "**Note:** If you are using the workspace, you will need to go to the terminal and run the command `conda update pandas` before reading in the files. This is because the version of pandas in the workspace cannot read in the transcript.json file correctly, but the newest version of pandas can. You can access the termnal from the orange icon in the top left of this notebook.  \n",
    "\n",
    "You can see how to access the terminal and how the install works using the two images below.  First you need to access the terminal:\n",
    "\n",
    "<img src=\"pic1.png\"/>\n",
    "\n",
    "Then you will want to run the above command:\n",
    "\n",
    "<img src=\"pic2.png\"/>\n",
    "\n",
    "Finally, when you enter back into the notebook (use the jupyter icon again), you should be able to run the below cell without any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import svm\n",
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#from xgboost import XGBClassifier\n",
    "%matplotlib inline\n",
    "\n",
    "# read in the json files\n",
    "portfolio = pd.read_json('portfolio.json', orient='records', lines=True)\n",
    "profile = pd.read_json('profile.json', orient='records', lines=True)\n",
    "# transcript = pd.read_json('transcript.json', orient='records', lines=True)\n",
    "transcript=pd.read_csv('transcript_expanded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bogo', 'informational', 'discount'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio['offer_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channels</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>id</th>\n",
       "      <th>offer_type</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[email, mobile, social]</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>ae264e3637204a6fb9bb56bc8210ddfd</td>\n",
       "      <td>bogo</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[web, email, mobile, social]</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4d5c57ea9a6940dd891ad53e9dbe8da0</td>\n",
       "      <td>bogo</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[web, email, mobile]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3f207df678b143eea3cee63160fa8bed</td>\n",
       "      <td>informational</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[web, email, mobile]</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9b98b8c7a33c4b65b9aebfe6a799e6d9</td>\n",
       "      <td>bogo</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[web, email]</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0b1e1539f2cc45b7b9fa7c272da2e1d7</td>\n",
       "      <td>discount</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       channels  difficulty  duration  \\\n",
       "0       [email, mobile, social]          10         7   \n",
       "1  [web, email, mobile, social]          10         5   \n",
       "2          [web, email, mobile]           0         4   \n",
       "3          [web, email, mobile]           5         7   \n",
       "4                  [web, email]          20        10   \n",
       "\n",
       "                                 id     offer_type  reward  \n",
       "0  ae264e3637204a6fb9bb56bc8210ddfd           bogo      10  \n",
       "1  4d5c57ea9a6940dd891ad53e9dbe8da0           bogo      10  \n",
       "2  3f207df678b143eea3cee63160fa8bed  informational       0  \n",
       "3  9b98b8c7a33c4b65b9aebfe6a799e6d9           bogo       5  \n",
       "4  0b1e1539f2cc45b7b9fa7c272da2e1d7       discount       5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>became_member_on</th>\n",
       "      <th>gender</th>\n",
       "      <th>id</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118</td>\n",
       "      <td>20170212</td>\n",
       "      <td>None</td>\n",
       "      <td>68be06ca386d4c31939f3a4f0e3dd783</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>20170715</td>\n",
       "      <td>F</td>\n",
       "      <td>0610b486422d4921ae7d2bf64640c50b</td>\n",
       "      <td>112000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>20180712</td>\n",
       "      <td>None</td>\n",
       "      <td>38fe809add3b4fcf9315a9694bb96ff5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>20170509</td>\n",
       "      <td>F</td>\n",
       "      <td>78afa995795e4d85b5d9ceeca43f5fef</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118</td>\n",
       "      <td>20170804</td>\n",
       "      <td>None</td>\n",
       "      <td>a03223e636434f42ac4c3df47e8bac43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  became_member_on gender                                id    income\n",
       "0  118          20170212   None  68be06ca386d4c31939f3a4f0e3dd783       NaN\n",
       "1   55          20170715      F  0610b486422d4921ae7d2bf64640c50b  112000.0\n",
       "2  118          20180712   None  38fe809add3b4fcf9315a9694bb96ff5       NaN\n",
       "3   75          20170509      F  78afa995795e4d85b5d9ceeca43f5fef  100000.0\n",
       "4  118          20170804   None  a03223e636434f42ac4c3df47e8bac43       NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.rename(columns={'id':'person'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning\n",
    "1. extract different values from transcript into different columns.\n",
    "2. offer_id into offer id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand value column in transcript\n",
    "# transcript=pd.concat([transcript, transcript['value'].apply(pd.Series)], axis=1)\n",
    "# transcript.to_csv('transcript_expanded.csv',index=False)\n",
    "\n",
    "transcript=pd.read_csv('transcript_expanded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column to ensure only one offer_id column\n",
    "transcript['offer_id_new']=np.where(transcript['offer id'].isnull() & transcript['offer_id'].notnull(),transcript['offer_id'],transcript['offer id'])\n",
    "\n",
    "#drop unnecessary offer_id columns\n",
    "transcript.drop(['offer id','offer_id'],axis=1,inplace=True)\n",
    "\n",
    "#rename offer_id column\n",
    "transcript.rename(columns={'offer_id_new':'offer_id'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio.rename(columns={'id':'offer_id'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript=transcript.merge(portfolio,how='left',on='offer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript['day_offer']=transcript['time']/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript=transcript.sort_values(['person','day_offer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cols(drop_cols,df,inplace=False):\n",
    "    df=df.drop(columns=drop_cols,axis=1,inplace=inplace)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols(['value','time','reward_y'],transcript,inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript.loc[transcript['event']=='offer received','sequence']=0\n",
    "transcript.loc[transcript['event']=='offer viewed','sequence']=1\n",
    "transcript.loc[transcript['event']=='transaction','sequence']=2\n",
    "transcript.loc[transcript['event']=='offer completed','sequence']=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_view_transacted2=transcript[['day_offer','offer_id','person','event']][(transcript['event']=='transaction') | (transcript['event']=='offer viewed')].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_clean=transcript.merge(offers_view_transacted2,how='left',on=['person','day_offer','event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_clean['offer_id']=np.where(transactions_clean['offer_id_x'].isnull(),transactions_clean['offer_id_y'],transactions_clean['offer_id_x'])\n",
    "\n",
    "drop_cols(['offer_id_x','offer_id_y'],transactions_clean,inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_clean=transactions_clean.merge(portfolio,how='left',on='offer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event', 'person', 'amount', 'reward_x', 'channels_x', 'difficulty_x',\n",
       "       'duration_x', 'offer_type_x', 'day_offer', 'sequence', 'offer_id',\n",
       "       'channels_y', 'difficulty_y', 'duration_y', 'offer_type_y', 'reward'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_clean['duration']=np.where(transactions_clean['duration_x'].isnull(),transactions_clean['duration_y'],transactions_clean['duration_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols(['duration_x','offer_type_x','difficulty_x','channels_x','duration_y'],transactions_clean,inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_clean.rename(columns={'channels_y':'channels','reward_x':'reward','difficulty_y':'difficulty','offer_type_y':'offer_type'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_viewed_transactions_completed=transactions_clean[(transactions_clean['event']=='offer viewed') | (transactions_clean['event']=='transaction') | (transactions_clean['event']=='offer completed')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_received=transactions_clean[transactions_clean['event']=='offer received'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "offers_viewed_transactions_completed['offer_id_previous'] = offers_viewed_transactions_completed.groupby(['person','offer_id'])['offer_id'].shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_viewed_transactions_completed['valid_completed']=np.where(offers_viewed_transactions_completed['offer_id_previous']==offers_viewed_transactions_completed['offer_id'],1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event', 'person', 'amount', 'reward', 'day_offer', 'sequence',\n",
       "       'offer_id', 'channels', 'difficulty', 'offer_type', 'reward',\n",
       "       'duration', 'offer_id_previous', 'valid_completed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers_viewed_transactions_completed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event', 'person', 'amount', 'reward', 'day_offer', 'sequence',\n",
       "       'offer_id', 'channels', 'difficulty', 'offer_type', 'reward',\n",
       "       'duration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers_received.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_received['offer_id_previous']=np.nan\n",
    "offers_received['valid_completed']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_clean2=offers_received.append(offers_viewed_transactions_completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_clean2=transactions_clean2.sort_values(['person','day_offer','event','offer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_clean2['diff_info']=transactions_clean2[(transactions_clean2['offer_type']=='informational') & ((transactions_clean2['event']=='offer received') | (transactions_clean2['event']=='transaction'))].groupby(['person','offer_id'])['day_offer'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_clean2['diff_bogo']=transactions_clean2[(transactions_clean2['offer_type']=='bogo') & ((transactions_clean2['event']=='offer received') | (transactions_clean2['event']=='offer completed'))].groupby(['person','offer_id'])['day_offer'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_clean2['diff_discount']=transactions_clean2[(transactions_clean2['offer_type']=='discount') & ((transactions_clean2['event']=='offer received') | (transactions_clean2['event']=='offer completed'))].groupby(['person','offer_id'])['day_offer'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_clean2['valid_completed_duration']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_clean2.loc[transactions_clean2['diff_info']<=transactions_clean2['duration'],'valid_completed_duration']=1\n",
    "transactions_clean2.loc[transactions_clean2['diff_discount']<=transactions_clean2['duration'],'valid_completed_duration']=1\n",
    "transactions_clean2.loc[transactions_clean2['diff_bogo']<=transactions_clean2['duration'],'valid_completed_duration']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_clean2['valid_completed_duration']=transactions_clean2['valid_completed_duration'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>person</th>\n",
       "      <th>amount</th>\n",
       "      <th>reward</th>\n",
       "      <th>day_offer</th>\n",
       "      <th>sequence</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>channels</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>offer_type</th>\n",
       "      <th>reward</th>\n",
       "      <th>duration</th>\n",
       "      <th>offer_id_previous</th>\n",
       "      <th>valid_completed</th>\n",
       "      <th>diff_info</th>\n",
       "      <th>diff_bogo</th>\n",
       "      <th>diff_discount</th>\n",
       "      <th>valid_completed_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>offer viewed</td>\n",
       "      <td>0009655768c64bdeb2e877511632db8f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5a8bc65990b245e5a138643cd4eb9837</td>\n",
       "      <td>[email, mobile, social]</td>\n",
       "      <td>0</td>\n",
       "      <td>informational</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transaction</td>\n",
       "      <td>0009655768c64bdeb2e877511632db8f</td>\n",
       "      <td>22.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5a8bc65990b245e5a138643cd4eb9837</td>\n",
       "      <td>[email, mobile, social]</td>\n",
       "      <td>0</td>\n",
       "      <td>informational</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5a8bc65990b245e5a138643cd4eb9837</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>offer viewed</td>\n",
       "      <td>0009655768c64bdeb2e877511632db8f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3f207df678b143eea3cee63160fa8bed</td>\n",
       "      <td>[web, email, mobile]</td>\n",
       "      <td>0</td>\n",
       "      <td>informational</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>offer completed</td>\n",
       "      <td>0009655768c64bdeb2e877511632db8f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>f19421c1d4aa40978ebb69ca19b0e20d</td>\n",
       "      <td>[web, email, mobile, social]</td>\n",
       "      <td>5</td>\n",
       "      <td>bogo</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>transaction</td>\n",
       "      <td>0009655768c64bdeb2e877511632db8f</td>\n",
       "      <td>8.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3f207df678b143eea3cee63160fa8bed</td>\n",
       "      <td>[web, email, mobile]</td>\n",
       "      <td>0</td>\n",
       "      <td>informational</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3f207df678b143eea3cee63160fa8bed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             event                            person  amount  reward  \\\n",
       "1     offer viewed  0009655768c64bdeb2e877511632db8f     NaN     NaN   \n",
       "2      transaction  0009655768c64bdeb2e877511632db8f   22.16     NaN   \n",
       "4     offer viewed  0009655768c64bdeb2e877511632db8f     NaN     NaN   \n",
       "7  offer completed  0009655768c64bdeb2e877511632db8f     NaN     5.0   \n",
       "6      transaction  0009655768c64bdeb2e877511632db8f    8.57     NaN   \n",
       "\n",
       "   day_offer  sequence                          offer_id  \\\n",
       "1       8.00       1.0  5a8bc65990b245e5a138643cd4eb9837   \n",
       "2       9.50       2.0  5a8bc65990b245e5a138643cd4eb9837   \n",
       "4      15.50       1.0  3f207df678b143eea3cee63160fa8bed   \n",
       "7      17.25       3.0  f19421c1d4aa40978ebb69ca19b0e20d   \n",
       "6      17.25       2.0  3f207df678b143eea3cee63160fa8bed   \n",
       "\n",
       "                       channels  difficulty     offer_type  reward  duration  \\\n",
       "1       [email, mobile, social]           0  informational       0       3.0   \n",
       "2       [email, mobile, social]           0  informational       0       3.0   \n",
       "4          [web, email, mobile]           0  informational       0       4.0   \n",
       "7  [web, email, mobile, social]           5           bogo       5       5.0   \n",
       "6          [web, email, mobile]           0  informational       0       4.0   \n",
       "\n",
       "                  offer_id_previous  valid_completed  diff_info  diff_bogo  \\\n",
       "1                               NaN              0.0        NaN        NaN   \n",
       "2  5a8bc65990b245e5a138643cd4eb9837              1.0       2.50        NaN   \n",
       "4                               NaN              0.0        NaN        NaN   \n",
       "7                               NaN              0.0        NaN       0.25   \n",
       "6  3f207df678b143eea3cee63160fa8bed              1.0       3.25        NaN   \n",
       "\n",
       "   diff_discount  valid_completed_duration  \n",
       "1            NaN                       0.0  \n",
       "2            NaN                       1.0  \n",
       "4            NaN                       0.0  \n",
       "7            NaN                       1.0  \n",
       "6            NaN                       1.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_clean2[(transactions_clean2['event']=='offer completed') | (transactions_clean2['event']=='offer viewed') | (transactions_clean2['event']=='transaction')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effective offers: (get group of people & IDs who have valid_completed & valid_completed_duration for \"offer completed\" & \"transaction\" - unique by person, offerID and offer type)\n",
    "- Bogo/discount: Received -> viewed -> transaction -> offer completed\n",
    "- Info: Received -> viewed -> transaction\n",
    "\n",
    "Ineffective offers: (get group of unique people & offer IDs who have any of the below but not valid_completed or valid_completed duration (unique))\n",
    "- Bogo/discount: Received -> transaction -> offer completed -> viewed\n",
    "- Bogo/discount: Received -> transaction -> offer completed \n",
    "- Bogo/discount: Received -> viewed\n",
    "- Info: Received -> viewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offers_prep(df,offer_type):\n",
    "    #split df by offer type\n",
    "    temp=df[df['offer_type']==offer_type].copy()\n",
    "    #tag effective offers, split and recombine table\n",
    "    temp['effective_offers']=np.where((temp['valid_completed']==1) & (temp['valid_completed_duration']==1),1,0)\n",
    "    ineffective_offers=temp[temp['effective_offers']==0].groupby(['person','offer_id']).sum().reset_index()[['person','offer_id']]\n",
    "    effective_offers=temp[temp['effective_offers']==1].groupby(['person','offer_id']).sum().reset_index()[['person','offer_id']]\n",
    "    #re-create new column flag\n",
    "    ineffective_offers['effective_offer']=0\n",
    "    effective_offers['effective_offer']=1\n",
    "    final_df=effective_offers.append(ineffective_offers)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "offers_bogo=offers_prep(transactions_clean2,'bogo');\n",
    "offers_info=offers_prep(transactions_clean2,'informational');\n",
    "offers_discount=offers_prep(transactions_clean2,'discount');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique people who received offers\n",
    "received_offers=pd.Series(transactions_clean2[transactions_clean2['event']=='offer received']['person'].unique())\n",
    "#get people who purchased but did not receive any offers\n",
    "no_received_offers=pd.Series(transactions_clean2[np.logical_not(transactions_clean2['person'].isin(received_offers))]['person'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_offers_df(df):\n",
    "    #define rename function\n",
    "    def rename(col_name,df):\n",
    "        df[col_name]=np.where(df[col_name]==col_name,1,0)\n",
    "        return df\n",
    "    #merge to get user profile and offer characteristics \n",
    "    df=df.merge(portfolio,how='left',on='offer_id')\n",
    "    df=df.merge(profile,how='left',on='person')\n",
    "    #convert channels into categorical variables\n",
    "    channels = df['channels'].apply(pd.Series)\n",
    "    channels = channels.rename(columns={0:'web',1:'email',2:'mobile',3:'social'})\n",
    "    df=pd.concat([df[:], channels[:]], axis=1)\n",
    "    rename('web',df)\n",
    "    rename('email',df)\n",
    "    rename('mobile',df)\n",
    "    rename('social',df)\n",
    "    df=drop_cols('channels',df)\n",
    "    #convert became_member_on into member tenure\n",
    "    df['year']=pd.Series([int(str(x)[:4]) for x in df['became_member_on']])\n",
    "    df['month']=pd.Series([int(str(x)[-3]) for x in df['became_member_on']])\n",
    "    df['day']=pd.Series([int(str(x)[-2:]) for x in df['became_member_on']])\n",
    "    df=drop_cols('became_member_on',df)\n",
    "    df.loc[df['year'] == 2018, 'membership_tenure_days'] = (30*df['month'])+df['day']\n",
    "    df.loc[df['year'] != 2018, 'membership_tenure_days'] = ((2018-df['year'])*365)+(30*df['month'])+df['day']\n",
    "    df=drop_cols(['year','month','day'],df)\n",
    "    #drop missing values\n",
    "    df.dropna(axis=0,inplace=True)\n",
    "    #get dummy variables for gender column\n",
    "    df=pd.concat([df[:],pd.get_dummies(df['gender'],prefix='gender')],axis=1)\n",
    "    df=drop_cols('gender',df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_bogo=prep_offers_df(offers_bogo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#check for missing values\n",
    "print(offers_bogo['gender'].isnull().sum()/len(offers_bogo))\n",
    "print(offers_bogo['income'].isnull().sum()/len(offers_bogo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 40,  59,  24,  55,  54,  28,  62,  88,  50,  94,  44,  52,  58,\n",
       "        47,  22,  71,  45,  57,  19,  86,  67,  61,  70,  56,  68,  20,\n",
       "        75,  74,  87,  53,  60,  63,  64,  39,  83,  46,  81,  84,  26,\n",
       "        32,  37,  51,  21,  66,  41,  77,  35,  36,  69,  80,  49,  65,\n",
       "        42,  29,  73,  72,  93,  78,  85,  48,  31,  30,  90,  33,  79,\n",
       "        18,  27,  43,  34,  25,  76,  38,  92,  96, 101,  23,  89,  91,\n",
       "        82,  95, 100,  99,  97,  98])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers_bogo['age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a34c73080>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a34c88668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "offers_bogo['age'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender_O                  0\n",
       "gender                    0\n",
       "offer_id                  0\n",
       "effective_offer           0\n",
       "channels                  0\n",
       "difficulty                0\n",
       "duration                  0\n",
       "offer_type                0\n",
       "reward                    0\n",
       "age                       0\n",
       "became_member_on          0\n",
       "income                    0\n",
       "gender_M                  0\n",
       "web                       0\n",
       "email                     0\n",
       "mobile                    0\n",
       "social                    0\n",
       "year                      0\n",
       "month                     0\n",
       "day                       0\n",
       "membership_tenure_days    0\n",
       "gender_F                  0\n",
       "person                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers_bogo.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [age, gender, income]\n",
       "Index: []"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers_bogo[['age','gender','income']][offers_bogo['income'].isnull()].head()\n",
    "#we can see that the age is not useful in the cases where gender and income are null. Hence, can drop these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_bogo.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_discount=prep_offers_df(offers_discount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special treatment for offers_info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_offers_info(df):    \n",
    "    #convert became_member_on into member tenure\n",
    "    df['year']=pd.Series([int(str(x)[:4]) for x in df['became_member_on']])\n",
    "    df['month']=pd.Series([int(str(x)[-3]) for x in df['became_member_on']])\n",
    "    df['day']=pd.Series([int(str(x)[-2:]) for x in df['became_member_on']])\n",
    "    df=drop_cols('became_member_on',df)\n",
    "    df.loc[df['year'] == 2018, 'membership_tenure_days'] = (30*df['month'])+df['day']\n",
    "    df.loc[df['year'] != 2018, 'membership_tenure_days'] = ((2018-df['year'])*365)+(30*df['month'])+df['day']\n",
    "    df=drop_cols(['year','month','day'],df)\n",
    "    #drop missing values\n",
    "    df.dropna(axis=0,inplace=True)\n",
    "    #get dummy variables for gender column\n",
    "    df=pd.concat([df[:],pd.get_dummies(df['gender'],prefix='gender')],axis=1)\n",
    "    df=drop_cols('gender',df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_info=offers_info.merge(portfolio,how='left',on='offer_id')\n",
    "offers_info=offers_info.merge(profile,how='left',on='person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_col(name,df=offers_info):\n",
    "    df[name]= np.nan\n",
    "    df.loc[pd.Series([name in df['channels'][x] for x in range(len(df['channels']))]),name]=1\n",
    "    df[name]=df[name].fillna(value=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_col('web')\n",
    "channel_col('email')\n",
    "channel_col('mobile')\n",
    "channel_col('social');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols('channels',offers_info,inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_info=prep_offers_info(offers_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transactions(df,offer_type):\n",
    "    temp=transactions_clean2[['person','amount','offer_id']][(transactions_clean2['event']=='transaction') & (transactions_clean2['offer_type']==offer_type)]\n",
    "    df=df.merge(temp,how='left',on=['person','offer_id'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_discount=get_transactions(offers_discount,'discount')\n",
    "offers_bogo=get_transactions(offers_bogo,'bogo')\n",
    "offers_info=get_transactions(offers_info,'informational')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 individual models - determine demographic types that would respond to each type of offer effectively. 3 types of offers, and one type which does not purchase any at all (only 20 records).\n",
    "\n",
    "Overall multiclass model - only for effective offers.\n",
    "Overall model - determine how much someone would spend depending on offer type and demographics.\n",
    "\n",
    "All in all, 6 total models.\n",
    "\n",
    "There may be people who viewed and completed offers (effective offers) but no transaction associated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1: Determine what are the drivers of effectiveness of bogo type offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "offers_bogo_tmp=offers_bogo.drop_duplicates(subset=['person','offer_id'])\n",
    "offers_discount_tmp=offers_discount.drop_duplicates(subset=['person','offer_id'])\n",
    "offers_info_tmp=offers_info.drop_duplicates(subset=['person','offer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effective_offer</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.587662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.412338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   person\n",
       "effective_offer          \n",
       "0                0.587662\n",
       "1                0.412338"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers_bogo_tmp[['person','effective_offer']].groupby('effective_offer').count()/len(offers_bogo_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effective_offer</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.54138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.45862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  person\n",
       "effective_offer         \n",
       "0                0.54138\n",
       "1                0.45862"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers_discount_tmp[['person','effective_offer']].groupby('effective_offer').count()/len(offers_discount_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effective_offer</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 person\n",
       "effective_offer        \n",
       "0                0.5375\n",
       "1                0.4625"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offers_info_tmp[['person','effective_offer']].groupby('effective_offer').count()/len(offers_info_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(df):\n",
    "    #drop unnecessary columns\n",
    "    drop_cols_offer=['offer_type','amount']\n",
    "    temp=drop_cols(drop_cols_offer,df)\n",
    "    # Split the data into features and target label\n",
    "    drop_cols_offer=['person','offer_id','effective_offer']\n",
    "    target = temp['effective_offer']\n",
    "    features = drop_cols(drop_cols_offer,temp)\n",
    "    return features,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(features,target):\n",
    "    #split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,target, \n",
    "                                                        test_size=0.20, \n",
    "                                                        random_state=42)\n",
    "    #fit and transform training data\n",
    "    poly = PolynomialFeatures(4)\n",
    "    X_train_poly=poly.fit_transform(X_train)\n",
    "    \n",
    "    #transform test data\n",
    "    X_test_poly=poly.transform(X_test)\n",
    "    \n",
    "    #fit and transform scaling on training data\n",
    "    scaler=StandardScaler()\n",
    "    X_train=scaler.fit_transform(X_train_poly)\n",
    "\n",
    "    #scale test data\n",
    "    X_test=scaler.transform(X_test_poly)\n",
    "    return X_train,X_test,y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features,target=data_prep(offers_bogo_tmp)\n",
    "X_train, X_test, y_train, y_test=model_pipeline(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: review_scores_rating training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: review_scores_rating testing set\n",
    "    '''\n",
    "    results = {}\n",
    "    \n",
    "    #Fit the learner to the training data and get training time\n",
    "    start = time() \n",
    "    learner = learner.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "    end = time() \n",
    "    results['train_time'] = end-start\n",
    "    \n",
    "    # Get predictions on the test set(X_test), then get predictions on first 300 training samples\n",
    "    start = time() \n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time() \n",
    "    \n",
    "    # Calculate the total prediction time\n",
    "    results['pred_time'] = end-start\n",
    "    \n",
    "    #Compute accuracy on the first 300 training samples\n",
    "    results['mse_train'] = mean_squared_error(y_train[:300],predictions_train)\n",
    "    \n",
    "    #Compute accuracy on test set\n",
    "    results['mse_test'] = mean_squared_error(y_test,predictions_test)\n",
    "    \n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "    print(\"MSE_train: %.4f\" % results['mse_train'])\n",
    "    print(\"MSE_test: %.4f\" % results['mse_test'])\n",
    "    print(\"Training score:%.4f\" % learner.score(X_train,y_train))\n",
    "    print(\"Test score:%.4f\" % learner.score(X_test,y_test))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(clf1,clf2):\n",
    "    # Calculate the number of samples for 1% and 100% of the training data\n",
    "    samples_100 = len(y_train)\n",
    "    samples_1 = int(0.01*len(y_train))\n",
    "\n",
    "    # Collect results on the learners\n",
    "    results = {}\n",
    "    for clf in [clf1, clf2]:\n",
    "        clf_name = clf.__class__.__name__\n",
    "        results[clf_name] = {}\n",
    "        for i, samples in enumerate([samples_1, samples_100]):\n",
    "            results[clf_name][i] = \\\n",
    "            train_predict(clf, samples, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the model\n",
    "clf1 = DecisionTreeClassifier(criterion='entropy',max_depth=5,random_state=2,min_samples_split=90,min_samples_leaf=50)\n",
    "clf2 = RandomForestClassifier(max_depth= 5, max_features= 'auto',min_samples_split= 10,n_estimators=20,min_samples_leaf=10)\n",
    "\n",
    "run_model(clf1,clf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features,target=data_prep(offers_discount)\n",
    "X_train, X_test, y_train, y_test=model_pipeline(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "features,target=data_prep(offers_info)\n",
    "X_train, X_test, y_train, y_test=model_pipeline(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def svc_param_selection(X, y):\n",
    "#     Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "#     gammas = [0.001, 0.01, 0.1, 1]\n",
    "#     kernel=['poly','rbf','linear','sigmoid']\n",
    "#     param_grid = {'C': Cs, 'gamma' : gammas,'kernel': kernel}\n",
    "#     grid_search = GridSearchCV(svm.SVC(random_state=2), param_grid)\n",
    "#     grid_search.fit(X, y)\n",
    "#     grid_search.best_params_\n",
    "#     return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rand_forest_param_selection(X,y):\n",
    "#     param_grid={'max_features': ['auto', 'sqrt'],\n",
    "#                 'max_depth' : [5,10],\n",
    "#                 'n_estimators': [20, 30, 40],\n",
    "#                 'min_samples_split': [2, 10, 20],\n",
    "#                 }\n",
    "#     grid_search = GridSearchCV(RandomForestClassifier(random_state=2), param_grid)\n",
    "#     grid_search.fit(X, y)\n",
    "#     grid_search.best_params_\n",
    "#     return grid_search.best_params_\n",
    "# rand_forest_param_selection(X_train[:samples_1], y_train[:samples_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append datasets together\n",
    "offers=offers_discount.append(offers_bogo)\n",
    "offers=offers.append(offers_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare multiclasses\n",
    "offers['type']=np.nan\n",
    "offers.loc[offers['offer_type']=='bogo','type']=0\n",
    "offers.loc[offers['offer_type']=='discount','type']=1\n",
    "offers.loc[offers['offer_type']=='informational','type']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data prep\n",
    "temp=drop_cols(['offer_type','amount'],offers)\n",
    "temp.drop_duplicates(subset=['person','offer_id','type'])\n",
    "drop_cols_offer=['person','offer_id','effective_offer']\n",
    "target = temp['effective_offer']\n",
    "features = drop_cols(drop_cols_offer,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=model_pipeline(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC trained on 1859 samples.\n",
      "MSE_train: 0.3700\n",
      "MSE_test: 0.3813\n",
      "Training score:0.6175\n",
      "Test score:0.6187\n"
     ]
    }
   ],
   "source": [
    "#Initialize the model\n",
    "clf1 = DecisionTreeClassifier(criterion='entropy',max_depth=5,random_state=2,min_samples_split=90,min_samples_leaf=50)\n",
    "clf2 = RandomForestClassifier(max_depth= 5, max_features= 'auto',min_samples_split= 10,n_estimators=20,min_samples_leaf=10)\n",
    "\n",
    "#run model\n",
    "run_model(clf1,clf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting feature engineering with polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(df):\n",
    "    #drop unnecessary columns\n",
    "    drop_cols_offer=['offer_type','amount']\n",
    "    temp=drop_cols(drop_cols_offer,df)\n",
    "    # Split the data into features and target label\n",
    "    drop_cols_offer=['person','offer_id','effective_offer']\n",
    "    target = temp['effective_offer']\n",
    "    features = drop_cols(drop_cols_offer,temp)\n",
    "    return features,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "features,target=data_prep(offers_bogo_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(features,target):\n",
    "    #split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,target, \n",
    "                                                        test_size=0.20, \n",
    "                                                        random_state=42)\n",
    "    #fit and transform training data\n",
    "    poly = PolynomialFeatures(2)\n",
    "    X_train_poly=poly.fit_transform(X_train)\n",
    "    \n",
    "    #transform test data\n",
    "    X_test_poly=poly.transform(X_test)\n",
    "    \n",
    "    #fit and transform scaling on training data\n",
    "    scaler=StandardScaler()\n",
    "    X_train=scaler.fit_transform(X_train_poly)\n",
    "\n",
    "    #scale test data\n",
    "    X_test=scaler.transform(X_test_poly)\n",
    "    return X_train,X_test,y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=model_pipeline(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: review_scores_rating training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: review_scores_rating testing set\n",
    "    '''\n",
    "    results = {}\n",
    "    \n",
    "    #Fit the learner to the training data and get training time\n",
    "    start = time() \n",
    "    learner = learner.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "    end = time() \n",
    "    results['train_time'] = end-start\n",
    "    \n",
    "    # Get predictions on the test set(X_test), then get predictions on first 300 training samples\n",
    "    start = time() \n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time() \n",
    "    \n",
    "    # Calculate the total prediction time\n",
    "    results['pred_time'] = end-start\n",
    "    \n",
    "    #Compute accuracy on the first 300 training samples\n",
    "    results['mse_train'] = mean_squared_error(y_train[:300],predictions_train)\n",
    "    \n",
    "    #Compute accuracy on test set\n",
    "    results['mse_test'] = mean_squared_error(y_test,predictions_test)\n",
    "    \n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "    print(\"MSE_train: %.4f\" % results['mse_train'])\n",
    "    print(\"MSE_test: %.4f\" % results['mse_test'])\n",
    "    print(\"Training score:%.4f\" % learner.score(X_train,y_train))\n",
    "    print(\"Test score:%.4f\" % learner.score(X_test,y_test))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(clf1,clf2,clf3):\n",
    "    # Calculate the number of samples for 1% and 100% of the training data\n",
    "    samples_100 = len(y_train)\n",
    "    samples_1 = int(0.01*len(y_train))\n",
    "\n",
    "    # Collect results on the learners\n",
    "    results = {}\n",
    "    for clf in [clf1, clf2,clf3]:\n",
    "        clf_name = clf.__class__.__name__\n",
    "        results[clf_name] = {}\n",
    "        for i, samples in enumerate([samples_1, samples_100]):\n",
    "            results[clf_name][i] = \\\n",
    "            train_predict(clf, samples, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC trained on 188 samples.\n",
      "MSE_train: 0.4100\n",
      "MSE_test: 0.4128\n",
      "Training score:0.5878\n",
      "Test score:0.5872\n",
      "SVC trained on 18895 samples.\n",
      "MSE_train: 0.3767\n",
      "MSE_test: 0.3876\n",
      "Training score:0.6206\n",
      "Test score:0.6124\n",
      "RandomForestClassifier trained on 188 samples.\n",
      "MSE_train: 0.3100\n",
      "MSE_test: 0.3821\n",
      "Training score:0.6263\n",
      "Test score:0.6179\n",
      "RandomForestClassifier trained on 18895 samples.\n",
      "MSE_train: 0.3400\n",
      "MSE_test: 0.3558\n",
      "Training score:0.6576\n",
      "Test score:0.6442\n",
      "DecisionTreeClassifier trained on 188 samples.\n",
      "MSE_train: 0.3667\n",
      "MSE_test: 0.3825\n",
      "Training score:0.6173\n",
      "Test score:0.6175\n",
      "DecisionTreeClassifier trained on 18895 samples.\n",
      "MSE_train: 0.3400\n",
      "MSE_test: 0.3692\n",
      "Training score:0.6455\n",
      "Test score:0.6308\n"
     ]
    }
   ],
   "source": [
    "#Initialize the model\n",
    "clf1 = svm.SVC(C= 0.1, gamma= 0.001, kernel= 'rbf')\n",
    "clf2 = RandomForestClassifier(max_depth= 5, max_features= 'auto',min_samples_split= 10,n_estimators=20,min_samples_leaf=10)\n",
    "clf3 = DecisionTreeClassifier(criterion='entropy',max_depth=5,random_state=2,min_samples_split=90,min_samples_leaf=50)\n",
    "\n",
    "run_model(clf1,clf2,clf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
